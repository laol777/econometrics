library("dplyr")
library("ggplot2")
library("GGally")
library("psych")

# 1. ѕостройте матрицу парных коэффициентов коррел€ции. ”становите какие факторы мультиколлинеарны.
# 2. ѕостройте уравнение множественной регрессии в линейной форме с полным набором факторов.
# 3. ќцените статистическую значимость уравнени€ регрессии и его параметров с помощью критериев ‘ишера и —тьюдента.
# ќтберите информативные факторы . ѕостройте уравнение со статистически значимыми факторами
# ќцените качество уравнени€ через среднюю ошибку аппроксимации


X = data.frame(y =  c(39,  68.4,34.8,39,54.7,74.7,71.7,74.5,137.7,40,53,86), #¬аловой доход за год
               x1 = c(20,40.5,16,20,28,46.3,45.9,47.5,87.2,17.7,31.1,48.7), #ќсновных фондов
               x2 = c(8.2,10.7,10.7,8.5,10.9,10.7,10.7,10.4,14.6,11,10,14)) #ќборотных средств



ggpairs(X)

linearModel_x1_x2 <- lm(y~x1 + x2, data = X)
linearModel_x1 <- lm(y~x1, data = X)
linearModel_x2 <- lm(y~x2, data = X)

result <- data.frame(y = X$y, 
                     x1_x2 = predict(linearModel_x1_x2), 
                     x1 = predict(linearModel_x1), 
                     x2 = predict(linearModel_x2))

# предполагаетс€, что выборки должны быть нормальными, чего нет, что с этим делать?
###############################проверка равенства средних############################
resultTtest <- data.frame(p_X1_X2 = t.test(result$y, result$x1_x2)$p.value,
                          p_X1 = t.test(result$y, result$x1)$p.value,
                          p_X2 = t.test(result$y, result$x2)$p.value)
# p_X1_X2 | p_X1 | p_X2
#   1     |   1  |   1
# можно с уверенностью сказать, что среднии равны, что на самом деле так - они все равны 64.45833
#####################################################################################


###############################проверка равенства дисперсий##########################
resultFishertest <- data.frame(p_X1_X2 = var.test(result$y, result$x1_x2)$p.value,  
                               p_X1 = var.test(result$y, result$x1)$p.value,
                               p_X2 = var.test(result$y, result$x2)$p.value)

# p_X1_X2 | p_X1  | p_X2
# 0.994   | 0.983 | 0.489

# можно сделать вывод, что дисперсии достаточно схожие с исходными, кроме модели, построенной
# на основании второй переменной - x2, причину этого можно увидеть, если посмотреть на гистограмму
# распределени€ признака - она координально отличаетс€ от y и x1

# 95 confidence interval
# y~x1 0.2916438 3.5191452
# y~x2 0.4416783 5.3295486
# y~x1_x2 0.2890907 3.4883381

#####################################################################################
sd_x1_x2 <- sd(result$y - result$x1_x2)
sd_x1 <- sd(result$y - result$x1)
sd_x2 <- sd(result$y - result$x2)


#summary(linearModel_x1_x2)
#summary(linearModel_x1)
#summary(linearModel_x2)


# вывод - оба признака достаточно значимы, дл€ построени€ модели, в чем можно убедитьс€,
# если посмотреть на среднеквадратичные отклонени€ моделей
# model_x1_x2 - 1.863
# model_x1 - 3.269
# model_x2 - 16.975